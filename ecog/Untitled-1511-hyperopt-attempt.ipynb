{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import io\n",
    "from scipy.signal import butter, lfilter\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from time import gmtime, strftime, time\n",
    "\n",
    "from nd_legacy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    \n",
    "    ecog_matfile = io.loadmat('test_ecog_data.mat')\n",
    "    raw_data = ecog_matfile['raw_data']\n",
    "    raw_acc = ecog_matfile['raw_acc']\n",
    "    mv_acc = ecog_matfile['mv_acc']\n",
    "\n",
    "    sampling_rate = 2000\n",
    "\n",
    "    raw_data = raw_data[:,0:-10000]\n",
    "    raw_acc = raw_acc[:,0:-10000]\n",
    "    mv_acc = mv_acc[:,0:-10000]\n",
    "\n",
    "    len_raw_data = raw_data.shape[1]\n",
    "    \n",
    "    raw_acc_f = butter_bandpass_filter(raw_acc, 0.1, 1, sampling_rate, order=3, how_to_filt = 'separately')\n",
    "\n",
    "    idxs_train = np.arange(0,len_raw_data//3);\n",
    "    idxs_val = np.arange(len_raw_data//3,len_raw_data//2);\n",
    "    idxs_test = np.arange(len_raw_data//2,len_raw_data - 1000);\n",
    "\n",
    "    raw_data_train = raw_data[4:8,idxs_train]\n",
    "    raw_data_val = raw_data[4:8,idxs_val]\n",
    "    raw_data_test = raw_data[4:8,idxs_test]\n",
    "\n",
    "    mv_acc_train = raw_acc_f[:,idxs_train]\n",
    "    mv_acc_val = raw_acc_f[:,idxs_val]\n",
    "    mv_acc_test = raw_acc_f[:,idxs_test]\n",
    "\n",
    "    def generate_slice(slice_len, pos=2, val=False):\n",
    "        if val:\n",
    "            X = raw_data_val\n",
    "            y = mv_acc_val\n",
    "        else:\n",
    "            X = raw_data_train\n",
    "            y = mv_acc_train\n",
    "\n",
    "        len_X = X.shape[1]\n",
    "\n",
    "        while True:\n",
    "            slice_start = np.random.choice(len_X - slice_len)\n",
    "            slice_end = slice_start + slice_len\n",
    "            slice_mid = slice_start + slice_len//2\n",
    "            slice_x = X[:,slice_start:slice_end].T\n",
    "\n",
    "            if pos==0:\n",
    "                slice_y = y[0,slice_start]\n",
    "            elif pos==1:\n",
    "                slice_y = y[0,slice_mid]\n",
    "            else:            \n",
    "                slice_y = y[0,slice_end]\n",
    "\n",
    "            return slice_x, slice_y\n",
    "\n",
    "    def train_generator(batch_size, slice_len, pos=2):\n",
    "        while True:\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "\n",
    "            for i in range(0, batch_size):\n",
    "                x, y = generate_slice(slice_len, pos, val=False)\n",
    "                batch_x.append(x)\n",
    "                batch_y.append(y)\n",
    "\n",
    "            y = np.array(batch_y)\n",
    "            x = np.array([i for i in batch_x])\n",
    "            yield (x, y)\n",
    "            \n",
    "    def validation_generator(batch_size, slice_len, pos=2):\n",
    "        while True:\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "\n",
    "            for i in range(0, batch_size):\n",
    "                x, y = generate_slice(slice_len, pos, val=True)\n",
    "                batch_x.append(x)\n",
    "                batch_y.append(y)\n",
    "\n",
    "            y = np.array(batch_y)\n",
    "            x = np.array([i for i in batch_x])\n",
    "            yield (x, y)\n",
    "\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas.distributions import choice, uniform, conditional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dense, maximum, Dropout, Input, merge, GlobalMaxPooling1D, MaxPooling1D, Flatten, LSTM, BatchNormalization\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(train_generator, validation_generator):\n",
    "\n",
    "    ###\n",
    "    \n",
    "    slice_len = 2000\n",
    "\n",
    "    nb_filters = 10\n",
    "    kernel_size = 50\n",
    "\n",
    "    pos = 2\n",
    "    \n",
    "    input_seq = Input(shape=(slice_len, 4))\n",
    "\n",
    "    inputbn = BatchNormalization(axis = -1)(input_seq)\n",
    "\n",
    "    convolved = Conv1D(nb_filters, kernel_size={{choice([50, 100, 200, 300, 500, 1000])}}, padding=\"same\", activation='elu', kernel_initializer='orthogonal')(inputbn)\n",
    "    convolvedbn = BatchNormalization(axis = -1)(convolved)\n",
    "    pooled = MaxPooling1D(pool_size=4)(convolvedbn)\n",
    "\n",
    "    convolved2 = Conv1D(nb_filters*4, kernel_size={{choice([50, 100, 200, 300, 500, 1000])}}, padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled)\n",
    "    convolved2bn = BatchNormalization(axis = -1)(convolved2)\n",
    "    pooled2 = MaxPooling1D(pool_size=4)(convolved2bn)\n",
    "\n",
    "    convolved3 = Conv1D(nb_filters*16, kernel_size={{choice([50, 100, 200, 300, 500, 1000])}}, padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled2)\n",
    "    convolved3bn = BatchNormalization(axis = -1)(convolved3)\n",
    "    pooled3 = MaxPooling1D(pool_size=4)(convolved3bn)\n",
    "\n",
    "    convolved4 = Conv1D(nb_filters*64, kernel_size={{choice([50, 100, 200, 300, 500, 1000])}}, padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled3)\n",
    "    convolved4bn = BatchNormalization(axis = -1)(convolved4)\n",
    "\n",
    "    flat = GlobalMaxPooling1D()(convolved4bn)\n",
    "\n",
    "    dense1 = maximum([Dense(1000, activation='linear', kernel_initializer='glorot_normal')(flat) for _ in range(3)])\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1do = Dropout(0.2)(dense1)\n",
    "\n",
    "    out = Dense(1, activation='linear')(dense1do) \n",
    "    model = Model(inputs=input_seq, outputs=out)\n",
    "\n",
    "    ###\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "    \n",
    "    ##\n",
    "\n",
    "    #path_to_save_model = \"1511_hyper_test\"\n",
    "\n",
    "    steps_per_epoch = 600\n",
    "    validation_steps = 300\n",
    "    epochs = 200\n",
    "    patience = 20\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    #earlyStopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=2, mode='auto')\n",
    "    #checkpointer = ModelCheckpoint(path_to_save_model, monitor='val_loss', verbose=2,\n",
    "    #                               save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "    model.fit_generator(train_generator(slice_len=slice_len, batch_size=batch_size), \n",
    "                        steps_per_epoch=steps_per_epoch, \n",
    "                        epochs=epochs, \n",
    "                        #callbacks=[earlyStopping, checkpointer], \n",
    "                        verbose=1, \n",
    "                        validation_steps=validation_steps, \n",
    "                        validation_data=validation_generator(slice_len=slice_len, batch_size=batch_size, pos=pos))\n",
    "\n",
    "    score, acc = model.evaluate_generator(data_generator(slice_len=slice_len, batch_size=batch_size, \n",
    "                                                     pos=pos, val=True),500)\n",
    "\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from scipy import io\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from scipy.signal import butter, lfilter\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import h5py\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from time import gmtime, strftime, time\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from nd_legacy import *\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv1D, Dense, maximum, Dropout, Input, merge, GlobalMaxPooling1D, MaxPooling1D, Flatten, LSTM, BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model, load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'kernel_size': hp.choice('kernel_size', [50, 100, 200, 300, 500, 1000]),\n",
      "        'kernel_size_1': hp.choice('kernel_size_1', [50, 100, 200, 300, 500, 1000]),\n",
      "        'kernel_size_2': hp.choice('kernel_size_2', [50, 100, 200, 300, 500, 1000]),\n",
      "        'kernel_size_3': hp.choice('kernel_size_3', [50, 100, 200, 300, 500, 1000]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \n",
      "   3: ecog_matfile = io.loadmat('test_ecog_data.mat')\n",
      "   4: raw_data = ecog_matfile['raw_data']\n",
      "   5: raw_acc = ecog_matfile['raw_acc']\n",
      "   6: mv_acc = ecog_matfile['mv_acc']\n",
      "   7: \n",
      "   8: sampling_rate = 2000\n",
      "   9: \n",
      "  10: raw_data = raw_data[:,0:-10000]\n",
      "  11: raw_acc = raw_acc[:,0:-10000]\n",
      "  12: mv_acc = mv_acc[:,0:-10000]\n",
      "  13: \n",
      "  14: len_raw_data = raw_data.shape[1]\n",
      "  15: \n",
      "  16: raw_acc_f = butter_bandpass_filter(raw_acc, 0.1, 1, sampling_rate, order=3, how_to_filt = 'separately')\n",
      "  17: \n",
      "  18: idxs_train = np.arange(0,len_raw_data//3);\n",
      "  19: idxs_val = np.arange(len_raw_data//3,len_raw_data//2);\n",
      "  20: idxs_test = np.arange(len_raw_data//2,len_raw_data - 1000);\n",
      "  21: \n",
      "  22: raw_data_train = raw_data[4:8,idxs_train]\n",
      "  23: raw_data_val = raw_data[4:8,idxs_val]\n",
      "  24: raw_data_test = raw_data[4:8,idxs_test]\n",
      "  25: \n",
      "  26: mv_acc_train = raw_acc_f[:,idxs_train]\n",
      "  27: mv_acc_val = raw_acc_f[:,idxs_val]\n",
      "  28: mv_acc_test = raw_acc_f[:,idxs_test]\n",
      "  29: \n",
      "  30: def generate_slice(slice_len, pos=2, val=False):\n",
      "  31:     if val:\n",
      "  32:         X = raw_data_val\n",
      "  33:         y = mv_acc_val\n",
      "  34:     else:\n",
      "  35:         X = raw_data_train\n",
      "  36:         y = mv_acc_train\n",
      "  37: \n",
      "  38:     len_X = X.shape[1]\n",
      "  39: \n",
      "  40:     while True:\n",
      "  41:         slice_start = np.random.choice(len_X - slice_len)\n",
      "  42:         slice_end = slice_start + slice_len\n",
      "  43:         slice_mid = slice_start + slice_len//2\n",
      "  44:         slice_x = X[:,slice_start:slice_end].T\n",
      "  45: \n",
      "  46:         if pos==0:\n",
      "  47:             slice_y = y[0,slice_start]\n",
      "  48:         elif pos==1:\n",
      "  49:             slice_y = y[0,slice_mid]\n",
      "  50:         else:            \n",
      "  51:             slice_y = y[0,slice_end]\n",
      "  52: \n",
      "  53:         return slice_x, slice_y\n",
      "  54: \n",
      "  55: def train_generator(batch_size, slice_len, pos=2):\n",
      "  56:     while True:\n",
      "  57:         batch_x = []\n",
      "  58:         batch_y = []\n",
      "  59: \n",
      "  60:         for i in range(0, batch_size):\n",
      "  61:             x, y = generate_slice(slice_len, pos, val=False)\n",
      "  62:             batch_x.append(x)\n",
      "  63:             batch_y.append(y)\n",
      "  64: \n",
      "  65:         y = np.array(batch_y)\n",
      "  66:         x = np.array([i for i in batch_x])\n",
      "  67:         yield (x, y)\n",
      "  68:         \n",
      "  69: def validation_generator(batch_size, slice_len, pos=2):\n",
      "  70:     while True:\n",
      "  71:         batch_x = []\n",
      "  72:         batch_y = []\n",
      "  73: \n",
      "  74:         for i in range(0, batch_size):\n",
      "  75:             x, y = generate_slice(slice_len, pos, val=True)\n",
      "  76:             batch_x.append(x)\n",
      "  77:             batch_y.append(y)\n",
      "  78: \n",
      "  79:         y = np.array(batch_y)\n",
      "  80:         x = np.array([i for i in batch_x])\n",
      "  81:         yield (x, y)\n",
      "  82: \n",
      "  83: \n",
      "  84: \n",
      "  85: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     ###\n",
      "   5:     \n",
      "   6:     slice_len = 2000\n",
      "   7: \n",
      "   8:     nb_filters = 10\n",
      "   9:     kernel_size = 50\n",
      "  10: \n",
      "  11:     pos = 2\n",
      "  12:     \n",
      "  13:     input_seq = Input(shape=(slice_len, 4))\n",
      "  14: \n",
      "  15:     inputbn = BatchNormalization(axis = -1)(input_seq)\n",
      "  16: \n",
      "  17:     convolved = Conv1D(nb_filters, kernel_size=space['kernel_size'], padding=\"same\", activation='elu', kernel_initializer='orthogonal')(inputbn)\n",
      "  18:     convolvedbn = BatchNormalization(axis = -1)(convolved)\n",
      "  19:     pooled = MaxPooling1D(pool_size=4)(convolvedbn)\n",
      "  20: \n",
      "  21:     convolved2 = Conv1D(nb_filters*4, kernel_size=space['kernel_size_1'], padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled)\n",
      "  22:     convolved2bn = BatchNormalization(axis = -1)(convolved2)\n",
      "  23:     pooled2 = MaxPooling1D(pool_size=4)(convolved2bn)\n",
      "  24: \n",
      "  25:     convolved3 = Conv1D(nb_filters*16, kernel_size=space['kernel_size_2'], padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled2)\n",
      "  26:     convolved3bn = BatchNormalization(axis = -1)(convolved3)\n",
      "  27:     pooled3 = MaxPooling1D(pool_size=4)(convolved3bn)\n",
      "  28: \n",
      "  29:     convolved4 = Conv1D(nb_filters*64, kernel_size=space['kernel_size_3'], padding=\"same\", activation='elu', kernel_initializer='orthogonal')(pooled3)\n",
      "  30:     convolved4bn = BatchNormalization(axis = -1)(convolved4)\n",
      "  31: \n",
      "  32:     flat = GlobalMaxPooling1D()(convolved4bn)\n",
      "  33: \n",
      "  34:     dense1 = maximum([Dense(1000, activation='linear', kernel_initializer='glorot_normal')(flat) for _ in range(3)])\n",
      "  35:     dense1 = BatchNormalization()(dense1)\n",
      "  36:     dense1do = Dropout(0.2)(dense1)\n",
      "  37: \n",
      "  38:     out = Dense(1, activation='linear')(dense1do) \n",
      "  39:     model = Model(inputs=input_seq, outputs=out)\n",
      "  40: \n",
      "  41:     ###\n",
      "  42: \n",
      "  43:     model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
      "  44:     \n",
      "  45:     ##\n",
      "  46: \n",
      "  47:     #path_to_save_model = \"1511_hyper_test\"\n",
      "  48: \n",
      "  49:     steps_per_epoch = 600\n",
      "  50:     validation_steps = 300\n",
      "  51:     epochs = 200\n",
      "  52:     patience = 20\n",
      "  53: \n",
      "  54:     batch_size = 16\n",
      "  55: \n",
      "  56:     #earlyStopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=2, mode='auto')\n",
      "  57:     #checkpointer = ModelCheckpoint(path_to_save_model, monitor='val_loss', verbose=2,\n",
      "  58:     #                               save_best_only=True, mode='auto', period=1)\n",
      "  59: \n",
      "  60:     model.fit_generator(train_generator(slice_len=slice_len, batch_size=batch_size), \n",
      "  61:                         steps_per_epoch=steps_per_epoch, \n",
      "  62:                         epochs=epochs, \n",
      "  63:                         #callbacks=[earlyStopping, checkpointer], \n",
      "  64:                         verbose=1, \n",
      "  65:                         validation_steps=validation_steps, \n",
      "  66:                         validation_data=validation_generator(slice_len=slice_len, batch_size=batch_size, pos=pos))\n",
      "  67: \n",
      "  68:     score, acc = model.evaluate_generator(data_generator(slice_len=slice_len, batch_size=batch_size, \n",
      "  69:                                                      pos=pos, val=True),500)\n",
      "  70: \n",
      "  71:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  72: \n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1000]\n\t [[Node: Variable_48/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_48\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_48, Const_53)]]\n\nCaused by op u'Variable_48/Assign', defined at:\n  File \"/home/ubuntu/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-22a4c4e7cb00>\", line 8, in <module>\n    notebook_name='Untitled-1511-hyperopt-attempt')\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.py\", line 136, in base_minimizer\n    return_argmin=True),\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"temp_model.py\", line 248, in keras_fmin_fnct\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1796, in fit_generator\n    self._make_train_function()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1014, in _make_train_function\n    self.total_loss)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 418, in get_updates\n    vs = [K.zeros(shape) for shape in shapes]\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 602, in zeros\n    dtype, name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 320, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 200, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 309, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 271, in assign\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 45, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1000]\n\t [[Node: Variable_48/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_48\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_48, Const_53)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-22a4c4e7cb00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                       notebook_name='Untitled-1511-hyperopt-attempt')\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation of best performing model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                      verbose=verbose)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.pyc\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    134\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     )\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtemp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1000]\n\t [[Node: Variable_48/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_48\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_48, Const_53)]]\n\nCaused by op u'Variable_48/Assign', defined at:\n  File \"/home/ubuntu/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-22a4c4e7cb00>\", line 8, in <module>\n    notebook_name='Untitled-1511-hyperopt-attempt')\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperas-0.4-py2.7.egg/hyperas/optim.py\", line 136, in base_minimizer\n    return_argmin=True),\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/hyperopt-0.1-py2.7.egg/hyperopt/base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"temp_model.py\", line 248, in keras_fmin_fnct\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1796, in fit_generator\n    self._make_train_function()\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1014, in _make_train_function\n    self.total_loss)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 418, in get_updates\n    vs = [K.zeros(shape) for shape in shapes]\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 602, in zeros\n    dtype, name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 320, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 200, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 309, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 271, in assign\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 45, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1000]\n\t [[Node: Variable_48/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_48\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_48, Const_53)]]\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Untitled-1511-hyperopt-attempt')\n",
    "\n",
    "print(\"Evaluation of best performing model:\")\n",
    "\n",
    "print(best_model.evaluate(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
